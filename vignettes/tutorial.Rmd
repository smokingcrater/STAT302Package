---
title: "STAT302Package Tutorial"
author: "Brad Scurlock"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{STAT302Package Tutorial}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

<!--- Begin styling code. --->
<style type="text/css">
/* Whole document: */
/*
body{
  font-family: "Palatino Linotype", "Book Antiqua", Palatino, serif;
  font-size: 12pt;
}
*/
h1.title {
  font-size: 38px;
  text-align: center;
}
h4.author {
  font-size: 18px;
  text-align: center;
}
</style>
<!--- End styling code. --->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r, setup, include = FALSE}
library(STAT302Package)
library(ggplot2)
library(dplyr)
library(kableExtra)
set.seed(617)
```

## **Introduction**

`STAT302Package` was developed as part of Project 3, the final project for STAT 302 (Statistical Computing) taught by Bryan Martin, PhD at the University of Washington.

`STAT302Package` is installed from GitHub using:

```{r, eval = FALSE}
devtools::install_github("smokingcrater/STAT302Package")
```

Once installed, `STAT302Package` is loaded as follows:

```{r eval = FALSE}
library(STAT302Package)
```

`STAT302Package` is comprised of four r functions: `my_t.test()`, `my_lm()`, `my_knn_cv()`, and `my_rf_cv()`.  Each function will be discussed below.

NOTE: Copies of the `gapminder` (from the `gapminder` package) and `penguins` (from the `palmerpenguins` package) data sets have been incorporated into `STAT302Package` and are named `my_gapminder` and `my_penguins`.

## **`my_t.test()`**

`my_t.test()` performs a one sample t-test in R and offers the same essential functionality as `t.test()` (from the `stats` package).

To demonstrate `my_t.test()`, we'll be analyzing life expectancy (`lifeExp`) from the `gapminder` data collection.  Prior to conducting hypothesis tests, let's review the life expectancy data.

```{r}
summary(my_gapminder$lifeExp)
```

NOTE: In the following three hypothesis tests, the significance level ($\alpha$) for p-value cut-off is 0.05; in other words, $\alpha = 0.05$.

**Hypothesis test 1 (two-sided/tailed t-test)**
\begin{align}
H_0: \mu &= 60,\\
H_a: \mu &\neq 60.
\end{align}

The following p-value is nominally greater than $\alpha$, thus indicating weak evidence against the null hypothesis.  *Therefore we fail to reject the null hypothesis*.

```{r}
my_t.test(my_gapminder$lifeExp, alternative = "two.sided", mu = 60)
```

**Hypothesis test 2 (one-sided/tailed t-test)**
\begin{align}
H_0: \mu &= 60,\\
H_a: \mu &< 60.
\end{align}

The following p-value is slightly less than $\alpha$, thus indicating strong evidence against the null hypothesis.  *Therefore we reject the null hypothesis*.

```{r}
my_t.test(my_gapminder$lifeExp, alternative = "less", mu = 60)
```

**Hypothesis test 3 (one-sided/tailed t-test)**
\begin{align}
H_0: \mu &= 60,\\
H_a: \mu &> 60.
\end{align}

The following p-value is significantly greater than $\alpha$, thus indicating weak evidence against the null hypothesis.  *Therefore we fail to reject the null hypothesis*.

```{r}
my_t.test(my_gapminder$lifeExp, alternative = "greater", mu = 60)
```


## **`my_lm()`**

my_lm() is a blah, blah, blah

```{r}
my_lm(formula = lifeExp ~ gdpPercap + continent, data = my_gapminder)
```

Linear regression was performed on the gapminder data set using lifeExp as the response variable (y) and gdpPercap and continent as the exploratory variables (x)

Carefully interpret the gdpPercap coefficient blah, blah, blah

```{r}
summary(my_gapminder$gdpPercap)
```

In the following hypothesis test, the significance level (alpha) for p-value cut-off is 0.05.

```{r}
my_t.test(my_gapminder$gdpPercap, alternative = "two.sided", mu = 7215.3)
```

The above p-value is substantially greater than alpha, thus indicating weak evidence against the null hypothesis.  Therefore we fail to reject the null hypothesis.

```{r}
# To obtain fitted values, multiply X %*% beta where:
#   X is the result of model.matrix()
#   beta represents the estimates returned from my_ln().
fitted_life_exp <-
  model.matrix(lifeExp ~ gdpPercap + continent, data = my_gapminder) %*%
  my_lm(formula = lifeExp ~ gdpPercap + continent, data = my_gapminder)[, 1]

# Create a data frame of the actual and fitted values along with their
# associated continent.
actual_vs_fit_df <-
  data.frame(actual = my_gapminder$lifeExp,
             fitted = fitted_life_exp,
             Continent = my_gapminder$continent)

# Plot actual vs fitted values and use color to distinguish continents.
ggplot(actual_vs_fit_df, aes(x = fitted, y = actual, col = Continent)) +
  geom_point(size = 0.75) +
  geom_abline(slope = 1, intercept = 0, col = "red", lty = 2) +
  theme_bw(base_size = 10) +
  labs(x = "Fitted values", y = "Actual values", title = "Actual vs. Fitted") +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"))
```

## **`my_knn_cv()`**

my_knn_cv() is a blah, blah, blah

```{r}
# Subset columns (classification = y = species, covariates = x =
# bill_length_mm, bill_depth_mm, flipper_length_mm, and body_mass_g)
# and eliminate NAs.
clean_penguins <-
  my_penguins %>%
  select(species,
         bill_length_mm, bill_depth_mm, flipper_length_mm, body_mass_g) %>%
  na.omit()

# Covariates (x data)..
my_train_nn <- clean_penguins %>% select(-species)
# Classification (y data).
my_cl <- clean_penguins$species

k <- 10
synopsis <- data.frame(
  "nn" = rep(NA, times =10),
  "cv_error" = rep(NA, times = 10),
  "training_error" = rep(NA, times = 10)
)
rn <- rep(NA, times = 10)

for (i in 1:k) {
  result <- my_knn_cv(train = my_train_nn, cl = my_cl, k_nn = i, k_cv = 5)
  synopsis[i, 1] <- i
  synopsis[i, 2] <- result$cv_err
  synopsis[i, 3] <- mean(my_cl != result$class)
}

colnames(synopsis) <- c("# of Nearest Neighbors",
                        "Cross Validation Misclassification Error",
                        "Training Set Misclassification Error")

kable_styling(kable(synopsis))
```

## **`my_rf_cv()`**

my_rf_cv() is a blah, blah, blah

```{r}
folds <- c(2, 5, 10)
iterations <- 3
results <- matrix(nrow = length(folds), ncol = iterations)
for (k in 1:length(folds)) {
  for (iteration in 1:iterations) {
    results[k, iteration] <- my_rf_cv(folds[k])
    cat("fold", k,
        "iteration", iteration,
        "value", results[k, iteration],
        "\n")
  }
}


mse_df <- data.frame(k = as.factor(rep(folds, each = 30)),
                     mse = c(results[1,], results[2,], results[3,]))

ggplot(data = mse_df, aes(x = k, y = mse)) +
  geom_boxplot(outlier.colour="red", outlier.shape=16,
               outlier.size=2, notch=TRUE) +
  theme_bw(base_size = 10) +
  labs(x = "k (number of folds)",
       y = "CV estimated MSE",
       title = "Cross Validation MSEs") +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"))


synopsis <- data.frame(
  "average" = rep(NA, times = nrow(results)),
  "stdev" = rep(NA, times = nrow(results))
)
rn <- rep(NA, times = nrow(results))

for (i in 1:length(folds)) {
  synopsis[i, 1] <- mean(results[i, ])
  synopsis[i, 2] <- sd(results[i, ])
  rn[i] <- paste("k (number of folds) = ", folds[i])
}

rownames(synopsis) <- rn
colnames(synopsis) <- c("Mean CV Estimate", "Standard Deviation CV Estimate")

kable_styling(kable(synopsis))
```

## **Conclusion**

In summary, blah, blah, blah
